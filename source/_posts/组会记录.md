## 组会记录

### 马师兄

> 该模型用与为音频进行标注，标注每个时间段几个人在说话

#### 训练集

1. 原始音频双人对话

2. Musan-speech加噪声

> 本课题主要专注于人声分离，因此将1中的对话与2中叠加形成噪声

#### F-bank滤波

1. 预加重

使用高通滤波器，缩小低频，以弥补人声在高频上的损失

> 实际处理时使用语谱图进行处理，对原本的时间-振幅图进行短时傅里叶变换，得到频域上的语谱图。

2. 分帧加窗口

窗口，一般将200帧定义为一个窗口，因为经验证明200帧以内的发音基本不变的同时保证一个窗口内的信息不至于过少。

步长，一般选择窗口的50%作为步长，因为这样可以保证能够保留相邻窗口之间信息的相互关系

加窗，这里使用汉明窗，即中间为1，两头为0，目的时为了避免边角信息的影响。

3. 短时傅里叶变换
4. mel滤波器

该滤波器用于模拟人耳的收听习惯，对低频更敏感，该滤波器主要保留了低频信息，主要是为了降低数据量

5. 取对数

将滤波后的数据取对数，使数据归一化，降低计算复杂度

#### Transformer-encoder

> 原模型使用了两个encoder，和4个头。本模型为原模型增加了两个encoder，改用8个头

##### 前两次encoder

用于说话人特征提取

改进后模型的错误率降低了9，75%

当增加到8层encoder时，错误率反而上升了，初步认为是数据不够支撑不起庞大的模型

原文中部分数据集获取不到

> 接下来会议对数据集的来源问题进行了讨论，部分数据集的来源无法写到论文中，当数据集获取困难时，偶尔需要自己制造数据，例如本实验中使用的对话数据集，可以对不同的单人语音进行合成从而得到对话数据。

