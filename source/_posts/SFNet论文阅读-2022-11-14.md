---
title: SFNet论文阅读
date: 2022-11-14 09:50:28
categories:
  - - 研究生
    - 科研
    - OCR
tags:
  - 手写体识别
  - 深度神经网络
  - 深度学习
  - 注意力机制
headimg:
  'https://z3.ax1x.com/2021/08/05/fego40.png'
plugins:
  - mathjax
---

## 摘要
本论文设计了：
1. **版面分析**：基于特征瀑布的多尺度融合模块，通过**不同尺度上的图像**进行相互融合进行版面分析
1. **混合数据识别**：阶段空间注意力模块，混合文本中存在二维空间结构，该模块在训练时能有效地注意到文本行中**二维结构的上下区域**，提升神经网络对二维特征的表达能力
1. **数据集**：真实场景下学生手写文本，分别构建了*混合检测*和*识别*数据集

### 实验结果

混合检测数据集：综合指标$F1^?$分数`91.1%`

混合识别数据集：准确率`83.33%`

## 方法

### 流程分析

数学文本识别流程：

1. 版面预处理
   1. 缩放、旋转、去噪
2. 文本行内部结构分析
   1. 通过语义分割将二维公式转化为一维序列
   2. 内部语义结构分析，将文字和公式分开处理
   3. 将数学公式划分为:
      1. 数值
      2. 根式
      3. 指数
      4. 分数
   4. 文本行整体分析
      1. 对真实场景下的手写体数学文档，进行了级别的标注

3. 识别模块
   1. 文本行序列识别


### 基于多尺度特征瀑布融合的检测网络

#### 思维基础

**特征金字塔网络(Feature Pyramid Network, FPN)**，该网络包含三条通路：

1. 自下而上的特征提取路径
2. 自上而下的特征强化路径
3. 横向连接

该方法相比于图像金字塔，该网络计算量更小，同事丰富每一层级的语义信息。

#### 多尺度特征瀑布融合模块

深层网络得到的特征图会有全局性的感受视野，含有强语义信息

浅层网络得到的特征图会有局部性的感受视野，还有丰富几何特征

本文中特征瀑布融合**(Feature Waterfall Fusion, FWF)**模块。

该模块包含三条通路：

1. 自下而上的特征提取路径(Bottom-up Pathway)
2. 特征融合的瀑布流路径(Waterfall-flow Pathway)
3. 横向连接(Lateral Connection)

![image-20221114142124732](https://s1.ax1x.com/2022/11/18/znfBPe.png)

特征提取路径使用ResNet输出四个不同尺寸的特征图，顶部特征图尺寸最小但语义信息最强，底部的图片分辨率最高语义信息最弱。

横向连接层首先使用一个kernel=1，stride=1，padding=0的卷积核将每一个特征图的通道数调整为固定值，上图中使用黄色异或符号表示

瀑布层会将箭头末端代表的特征图融合进箭头指向的特征图中，融合规则如下所示：

> 某层的特征将被其下所有层融合

即如图右侧最顶层特征将被其下三层融合。

融合方式类似瀑布，因此而的名称。

融合方式，以左侧虚线框中4层与1层合并为例：

1. 使用双线性插值法进行8倍上采样
2. 同像素累加
3. 由于上卷积存在混叠效应，最后需要通过kernel=3，stride=1，padding=1的卷积进行特征平滑操作

由于需要进行同像素累加操作，第2层与第1层的融合则只需要进行2倍上采样即可，如右侧虚线框中所示。

该模块的主要特征是，相比特征金字塔只将低分辨率特征图加入与其最近的一次特征图中，本模块**瀑布式**的将低分辨率特征图加入到其下的每一层，是所有特征图都具有较强的语义信息。

### 文本检测网络

在ResNet的基础上结合瀑布式融合模块

![image-20221114190810247](https://s1.ax1x.com/2022/11/18/znfD8H.png)

最后的$F_f$用于预测文本框，由4个特征图组成，拼接之前对$P_i$分别做上采样，使得通道数为D，长宽分别为$\frac{H}{4},\frac{W}{4}$，最后得到$F_f \in R^{4D\times H \times W}$

### 渐进式规模扩张后处理

**后处理采用渐进式规模扩张后处理(Progressive Scale Expansion, PSE)**

该算法的核心思想来源于BFS

![image-20221114195123132](https://s1.ax1x.com/2022/11/18/znfr2d.png)

计算伪代码如下：

![image-20221114195235947](https://s1.ax1x.com/2022/11/18/znf6KI.png)

其中符号T和P式算法扩张产生的中间结果，Queue表示队列，Neighbor()表示文本像素p的相邻像素集，符号GroupByLabel()式根据Label对中间结果分组的操作，符号$S_i[q] = True$表示像素q被预测为实列内核$S_i$的一部分

### 手写文字公式混合识别

#### 研究难点

1. 数据集较少
2. 书写风格不同
3. 版面随意

#### 基于阶段空间注意力的识别网络

##### 卷积注意力模块

卷积注意力模块(Convolutional Block Attention Module, CBAM)通过提升模型对图像中关键区域的表达能力，告诉网络该注意图片的什么地方，在图片的空间维度上和通道维度上对特征进行一直或强化。

![image-20221115105221857](https://s1.ax1x.com/2022/11/18/znfsxA.png)

该模块首先根据**通道注意力机制**产生一个尺寸为$R^{C\times 1\times 1}$的一维注意力图，与F进行像素相乘，得到中间结果$F'\in R^{C \times W \times H}$，然后再通过空间注意力图机制产生一个尺寸为$R^{1\times H\times W}$的二维注意力图，与$F'$进行像素相乘最后输出包含通道和空间两个维度权重的特征图$F''\in R^{C\times H\times W}$

#### 阶段空间注意力（Stage Spatial Attention， SSA）

在手写体数学文本行识别任务中，告诉模型重要区域在哪能提升识别准确率，因此此处指采用卷积注意力模块中的**空间注意力子模块**来捕获公式的二维结构，而不采用通道注意力子模块

![image-20221115110006102](https://s1.ax1x.com/2022/11/18/znfcrt.png)

如图所示的过程是SSA中提取出空间注意力图的过程：

1. 首先对输入的中间特征$F'$进行一次通道维度上的**最大池化（Max-Pool）**得到$F^s_{max} \in R^{1 \times H \times W}$，即蓝色区域
2. 然后对输入的中间特征$F'$进行一次通道维度上的**平均池化（Avg-Pool）**得到$F^s_{avg} \in R^{1 \times H \times W}$，即蓝色区域
3. 对$F^s_{max}$和$F^s_{avg}$按照相同位置进行像素拼接操作，得到$F^s \in R^{2\times H \times W}$
4. 接下来通过kernel=3,stride=1,padding=3的卷积核将通道数调整为1
5. 为了抑制和凸显重要区域，用Sigmoid函数将特征图上的值域压缩为0-1之间，得到$M_s$
6. 最后将$M_s$与输入特征图$F$进行像素乘法，就得到了空间注意力特征图

### 识别网络构建

由于**残差网络（ResNet）**本身的分成结构，本网络使用残差网络作为基础架构

![image-20221115141230291](https://s1.ax1x.com/2022/11/18/znfgqP.png)

该结构使用了5类残差网块，分别是RestNet18、RestNet34、RestNet50、RestNet101、RestNet152，此处省略了第一次卷积运算，对于任何$F \in R^{C \times H \times W}$的原始输入图片，残差神经网络分别四次输出中间的特征图：

$\{C_2 \in R^{c_2 \times \frac{H}{4} \times \frac{W}{4}}、C_3 \in R^{c_3 \times \frac{H}{8} \times \frac{W}{4}}、C_4 \in R^{c_4 \times \frac{H}{16} \times \frac{W}{4}}、C_5 \in R^{c_5 \times \frac{H}{32} \times \frac{W}{4}}\}$

因此每一个阶段空间注意力模块会分别生成注意力图：

$\{S_2 \in R^{c_2 \times \frac{H}{4} \times \frac{W}{4}}、S_3 \in R^{c_3 \times \frac{H}{8} \times \frac{W}{4}}、S_4 \in R^{c_4 \times \frac{H}{16} \times \frac{W}{4}}、S_5 \in R^{c_5 \times \frac{H}{32} \times \frac{W}{4}}\}$

该网络参数表如下：

![image-20221115142245054](https://s1.ax1x.com/2022/11/18/znffIS.png)

## 总体设计

1. 手写数学文档文本行的检测使用渐进式规模扩张后处理算法，该方法能分离间距紧密的文本实列
2. 混合文本序列识别采用卷积神经网络CNN和循环神经网络RNN的框架结构
   1. CNN使用嵌入有阶段空间注意力的ResNet
   2. RNN为双向LSTM
   3. 损失函数为CTC

![image-20221115152921036](https://s1.ax1x.com/2022/11/18/znfRVf.png)

## 分割网络损失函数设计

使用类似聚类算法的思想对文本行像素进行聚类，采用类似**像素聚合网络（Pixel Aggregation Net, PANet）**的损失函数，生成两个掩码标签：完整掩码和内核掩码

整体损失函数如下：

$L = L_{tex} + \alpha \times L_{ker} + \beta \times (L_{agg} + L_{dig})$

其中$L_{agg}$用来促使不属于内核K的像素与其之间距离大，属于内核K的像素与其保持较近距离：

$L_{agg} = \frac{1}{N} \sum ^N _{i=1} \frac{1}{|S_i|} \sum _ {p \in S_i} ln(D(p, K_i) +1)$

$D(p,K_i) = max(||F(p) - G(K_i)|| - \sigma _ {agg}, 0)^2$

1. $N$表示文档中所有文本行的实例总和
2. $S_i$表示一行文本行实列
3. $D(p, K_i)$定义了属于$S_i$的像素$p$和文本内核$K_i$之间的距离
4. 超参数$\sigma _ {agg}$设为0.5，用来过滤比较简单的数据
5. $F(p)$是像素$p$的相似度向量表示
6. $G(K_i)$是内核$K_i$的相似度向量表示

$L_{dis}$用来保证不同内核之间的距离足够大：

$L_{dis} = \frac{1}{N \times (N-1)}\sum^N _{i=1} \sum ^ N _ {j = 1, j \neq i} ln(D(K_i, K) + 1)$

$D(K_i, K_j) = max(\sigma _{dis} - ||G(K_i) - G(K_j)||, 0)^2$

1. 超参数$\sigma_{dis}$设置为3，用来保证不同内核之间的距离的绝对值要大于$\sigma_{dis}$

$L_{tex}$和$L_{ker}$分别作为文本区域和文本内核的损失，*考虑到文本行区域和非文本行区域分布的不平衡性*使用**Dice Loss**计算文本实列的分割结果$P_{tex}$和文本内核的分割结果$P_{ker}$：

$L_{tex} = 1 - \frac {2 \times \sum P_{tex}(i)\times G_{tex}(i)}{\sum P_{tex}(i)^2 + \sum G_{tex}(i)^2}$

$L_{ker} = 1 - \frac {2 \times \sum P_{ker}(i)\times G_{ker}(i)}{\sum P_{ker}(i)^2 + \sum G_{ker}(i)^2}$

$\alpha$和$\beta$两个超参数用来协调四个部分，分别被设置为0.5和0.25，学习率设置为0.001，使用**权重衰减**来避免过拟合，设置为0.0005，迭代次数设置为300

结果采用F1分数，即H-mean进行衡量，同事保持较高的精确率和召回率：

$F_1 = \frac{2\times Precision \times Recall}{Precision \times Recall}$

$Precision = \frac{TP}{TP + FP}$

$Recall = \frac{TP}{TP + FN}$

对比结果：

![image-20221115163754018](https://s1.ax1x.com/2022/11/18/znfWa8.png)

## 序列识别损失函数设计

训练使用**CTC(Connectionist Temporal Classification)**进行模型优化

采用Adam优化器对网络进行训练，学习率设置为0.001，迭代次数设置为100

效果对比

![image-20221115164347671](https://s1.ax1x.com/2022/11/18/znf4Pg.png)

## 缺陷

1. 文本行内部结构分析中，上游语义分割误差会影响到下游识别模块的性能，造成累计误差。
2. 进行行内部结构分析人工标注工作量大
3. 手写文本行内容倾斜问题比较突出，本位未对文本行进行图像校正
4. 本文使用的数据集规模较小，可以使用GAN网络来生成更多更逼真的数据。