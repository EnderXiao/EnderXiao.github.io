---
title: 图形学入门
date: 2022-01-09 11:00:13
categories:
  - - 计算机图形学
    - 图形学入门
tags:
  - 计算机图形学
mathjax: true
headimg:
  'https://z3.ax1x.com/2021/08/05/fegbgU.jpg'
---

下定决心开始学图形学
<!-- more -->

## 绪论

### 什么是图形学

> 从技术层面而言，画面越亮，全局光照越强，技术越好，画面越好

图形学的基本工业应用有如下一些场景：

1. 游戏
2. 电影
   1. 特效的制作，从某个方面来说特效是图形学中较好实现的，因为生活中比较少见
   2. 面部，动作捕捉
3. 渲染
   1. 毛发，几何形体的表述
   2. 渲染，光纤在几何形体中的传播与反射
   3. 粒子效果，模拟与动画
4. 设计
   1. CAD设计
   2. 室内设计
5. 可视化
   1. 人体可视化
6. VR
7. 数字绘画
8. 模拟
   1. 物理模拟
   2. 光线模拟
9. GUI
10. Typography字体表示
    1. The Quick Brown Fox Jumps Over The Lazy Dog，常用于测试字体的完整性，因为这一句话包含了所有26个字母

### 图形学中的问题

1. Math of （perspective）Projections, curves, surfaces
2. Physics of lighting and shading
3. Representing/Operating shapes in 3D
4. Animation/Simulation

### 光栅化

> 将三维空间的几何形体显示在屏幕上的过程称为光栅化

常用于**实时**计算机图形学（例如游戏）。

在计算机图形学中实时意味着每秒钟生成30副图像（帧），就认为是实时，否则认为是离线

### 几何

Curves和Meshes的表示

即曲线与曲面的表示，在变化过程中如何保持曲线与曲面的拓扑结构

### 光纤追踪

Calculate Intersection and shading

Continue to bounce the rays till they hit light sources

### 动画/仿真

- Key frame Animation
- Mass-spring System

### CV与CG的区别

CG注重建模，模拟，CV注重图像处理（图像分割等设计猜测和推理的操作）

## 图形学中的线性代数

图形学主要基于以下自然学科：

1. 基础数学：
   1. 线性代数
   2. 微积分
   3. 统计
2. 基础物理
   1. 光学
   2. 力学
   3. 波动光学等等
3. 其他
   1. 信号处理
   2. 数值分析（大量）
   3. 美学（一点点）

### 向量

数学上更习惯于称为向量

物理上更习惯于称为矢量

向量最重要的两个属性：

1. 方向
2. 长度

#### 向量标准化

1. 向量长度$||\vec {a}||$
2. 单位向量：
   1. 模长（magnitude）为1的向量
   2. 向量标准化：$\hat{a} = \vec{a} / ||\vec{a}||$
   3. 用于表示方向，不关心她的长度

#### 向量加

平行四边形法则：向量首首相接的平行四边形对角线

三角形法则：向量首尾相接形成的三角形第三条边

![image-20220109133346220](D:\EnderBlog\EnderXiao.github.io\source\images\image-20220109133346220.png)

在数学上的向量是基于一组基表示的，通常为笛卡尔基（即（1，0）与（0，1）），那么在这种情况下相加则为各坐标分量之和，便于计算向量长度。

#### 向量乘法

##### 点乘

![image-20220109133834463](D:\EnderBlog\EnderXiao.github.io\source\images\image-20220109133834463.png)

$\vec{a} \cdot \vec{b} = |\vec{a}||\vec{b}|cos\theta$

向量的点乘将得到一个数。

在图形学中，点乘可以用于计算出两个夹角的余弦，当两个向量均为单位向量时，点乘直接为夹角余弦：

$cos\theta = \frac{\vec a \cdot \vec b}{|\vec a||\vec b|} = \hat a \cdot \hat b$

写成矩阵形式如下：

$\vec a \cdot \vec b = {\vec a}^T \vec b$

点乘满足以下定律：

1. 交换律
2. 结合律
3. 分配律

此外，点乘还能用于计算投影：

![image-20220109134453383](D:\EnderBlog\EnderXiao.github.io\source\images\image-20220109134453383.png)

$ \vec {b_\perp} = k \hat a = |\vec b| cos\theta \hat a = |\vec b| (\hat a \cdot \hat b) \hat a$

利用投影我们可以将一个向量分解为两个相互垂直的向量：

![image-20220109134915827](D:\EnderBlog\EnderXiao.github.io\source\images\image-20220109134915827.png)

还能通过余弦相似度衡量两个向量的接近程度。

此外，考虑如下情况：

![image-20220109135213309](D:\EnderBlog\EnderXiao.github.io\source\images\image-20220109135213309.png)

通过余弦函数对钝角与锐角的响应的正负不同，可以判断两个向量的方向是相同还是相反

##### 叉乘

叉乘包括两个输入向量和一个输出向量。最终输出的向量为一个垂直于两个输入向量的新向量，且该向量的大小为：

$|\vec a \times \vec b| = |\vec a||\vec b| sin \phi$

其中$\phi$为向量夹角。

计算公式如下：

$\vec a \times \vec b = (y_az_b - y_bz_a, z_ax_b - x_az_b, x_ay_b - y_ax_b)^T$

其中$\vec a = (x_a,y_a,z_a), \vec b = (x_b,y_b,z_b)$

还能使用矩阵表示法：

$$
\vec a \times \vec b = A^{*}b = 
\left(
\begin{matrix}
0 & -z_a & y_a \\
z_a & 0 & -x_a \\
-y_a & x_a & 0 \\
\end{matrix}
\right)
\left(
\begin{matrix}
x_b \\
y_b \\
z_b \\
\end{matrix}
\right)
$$

其中$A^{*}$称为a的dual matrix。

输出向量的方向由右手准则确定。

在三位空间中，给定两个轴，可以使用叉乘计算出第三个轴。如果在一个三维坐标系中，x与y的叉乘得到z，则认为该坐标系为一个**右手坐标系**。

叉乘满足以下性质：

1. $\vec a \times \vec b = -\vec b \times \vec a$
2. $\vec a \times \vec a = \vec 0$
3. $\vec a \times (\vec b + \vec c) = \vec a \times \vec b + \vec a \times \vec c$ 分配率
4. $\vec a \times (k\vec b) = k (\vec a \times \vec b)$ 数乘结合律

在图形学中，可以利用叉乘来计算：

1. 一个向量在另一向量的左侧还是右侧
2. 一个向量在一个物体的内测还是外侧

例如对于如下一个x,y平面（z轴垂直于纸面），可以通过$\vec a$与$\vec b$的叉乘的正负判断b在a的左侧还是右侧：

![image-20220109142021592](D:\EnderBlog\EnderXiao.github.io\source\images\image-20220109142021592.png)

再比如对于如下情况，如何判断P点是否在三角形ABC内部：
![image-20220109142313403](D:\EnderBlog\EnderXiao.github.io\source\images\image-20220109142313403.png)

判断过程如下：

1. 计算AB与AP的叉乘，得到方向为z轴正方向，P在AB左侧
2. 计算BP与BC的叉乘，得到结果为z轴正方向，P在BC左侧
3. 计算CP与CA的叉乘，得到结果为z轴正方向，P在CA左侧

那么就可以认为P在三角形的内部。**即判断P点是否在三条边的同侧**

#### 坐标系

有了点乘和叉乘，就可以构造三维坐标系，考虑构造如下坐标系：
$$
|\vec u| = |\vec v| = |\vec w| = 1 \\
\vec u \cdot \vec v = \vec v \cdot \vec w = \vec u \cdot \vec w = 0 \\
\vec w = \vec u \times \vec v (right-handed) \\
\vec p = (\vec p \cdot \vec u)\vec u + (\vec p \cdot \vec v) \vec v + (\vec p \cdot \vec w)\vec w
$$
可见对于任意三维向量P，可以将其分解到这个坐标系

### 矩阵

#### 矩阵乘法

$(M \times N)(N \times P) = (M \times P)$

其中矩阵$(M \times P) = C$中的元素$c_{ij}$等于矩阵$(M \times N) = A$的第i行表示的向量，点乘，矩阵$(N \times P) = B$的第j列表示的向量。

矩阵乘法满足以下定律：

1. 结合律
2. 分配律（左分配率，右分配律）

#### 矩阵的转置

转置具有以下性质：

$(AB)^T = B^TA^T$

#### 特殊矩阵

1. 单位矩阵
2. 对角矩阵
3. 逆矩阵，由性质：$(AB)^{-1} = B^{-1}A^{-1}$

#### 矩阵变换

使用矩阵与向量的乘积操作，可以完成向量在坐标系下的变换，例如二维的y轴对称变换：
$$
\left(
\begin{matrix}
-1 & 0 \\
0 & 1
\end{matrix}
\right)
\left(
\begin{matrix}
x\\
y
\end{matrix}
\right) = 
\left(
\begin{matrix}
-x \\
y
\end{matrix}
\right)
$$

## 变换

变换可以大致分为以下两个方面：

1. Modeling，模型变换
2. Viewing，视图变换

例如在逆运动学中的应用。

1. 正运动学：已知各个关节的角度，求末端的位置
2. 逆运动学（IK,inverse kinematics）：已知末端的位置，求各个关节的角度

### 二维线性变换

#### 缩放

二维缩放操作可以用如下数学形式表示：
$$
x' = s_x x \\
y' = s_y y
$$
写成矩阵形式为：
$$
\left(
\begin{matrix}
x' \\
y'
\end{matrix}
\right) = 
\left(
\begin{matrix}
s_x & 0 \\
0 & s_y
\end{matrix}
\right)
\left(
\begin{matrix}
x \\
y
\end{matrix}
\right)
$$

#### 反射

二维反射可以用如下数学形式表示：
$$
\left(
\begin{matrix}
x' \\
y'
\end{matrix}
\right) = 
\left(
\begin{matrix}
-1 & 0 \\
0 & 1
\end{matrix}
\right)
\left(
\begin{matrix}
x \\
y
\end{matrix}
\right)
$$
上述操作使得物体按y轴反射

#### 切变（Shear）

![image-20220109150600560](D:\EnderBlog\EnderXiao.github.io\source\images\image-20220109150600560.png)

注意该变换有如下特点：

1. 垂直方向的坐标并未改变
2. 水平方向上，当y=0时，也不发生变换
3. 水平方向上，当y=1时，原坐标0移动了a个单位

通过观察可以发现水平方向上移动的距离可以用ay来表示，因此该变换可以用如下形式表示：
$$
\left(
\begin{matrix}
x' \\
y'
\end{matrix}
\right) = 
\left(
\begin{matrix}
1 & a \\
0 & 1
\end{matrix}
\right)
\left(
\begin{matrix}
x \\
y
\end{matrix}
\right)
$$

#### 旋转（Rotate）

此处讨论绕原点逆时针旋转。

我们可以利用特殊点得到旋转的变换矩阵（前提是旋转为线性变换）：

![image-20220109151729385](D:\EnderBlog\EnderXiao.github.io\source\images\image-20220109151729385.png)

最终得到的变换矩阵为：
$$
\left(
\begin{matrix}
cos\theta & -sin\theta \\
sin\theta & cos\theta
\end{matrix}
\right)
$$

#### 总结

对于上述的可以表示为矩阵乘以向量得到的变换称为线性变换

## 变换

### 齐次坐标（Homogeneous Coordinates）

齐次坐标的引入：平移坐标变换的特殊性

若需要将平移变换表示为矩阵形式，那么只能使用如下发给发进行
$$
\left(
\begin{matrix}
x' \\
y'
\end{matrix}
\right) = 
\left(
\begin{matrix}
a & b \\
c & d
\end{matrix}
\right)
\left(
\begin{matrix}
x \\
y
\end{matrix}
\right) + 
\left(
\begin{matrix}
t_x \\
t_y
\end{matrix}
\right)
$$
说明平移变换不再属于线性变换。

但我们希望用一个更鲁棒的方式来表示这些变换。

于是我们在原有的维度上增加一个维度，以二维为例：

- 表示一个二维的点：$point = (x,y,1)^T$
- 表示一个二维的向量：$vector = (x,y,0)^T$

为什么要用0和1去区分点和向量呢（怎么有点脆皮鸭内味）

原因是向量具有平移不变性，我们希望对向量进行平移操作时不会导致向量的改变。

更进一步，我们希望在齐次坐标系下，点和向量之间应依然存在如下关系：
$$
vector + vector = vector \\
point - point = point \\
point + vector = point \\
point + point = ??
$$
对于其次坐标系下的的点的加法的定义我们仍然需要进行扩充，考虑相加之后得到的数据：
$$
\left(
\begin{matrix}
x_1 \\
y_1 \\
w_1
\end{matrix}
\right) +
\left(
\begin{matrix}
x_2 \\
y_2 \\
w_2
\end{matrix}
\right) =
\left(
\begin{matrix}
(x_1+x_2)/(w_1+w_2) \\
(y_1 + y_2)/(w_1 + w_2) \\
1
\end{matrix}
\right)
$$
若两个数据均为其次坐标系下的点，那么$w_1 = w_2 = 1$，于是该加法就能用于表示两个点的中点。

最后在其次坐标下使用矩阵表示变换就能使用如下形式：
$$
\left(
\begin{matrix}
x' \\
y' \\
w'
\end{matrix}
\right) = 
\left(
\begin{matrix}
1 & 0 & t_x \\
0 & 1 & t_y \\
0 & 0 & 1
\end{matrix}
\right)
\left(
\begin{matrix}
x \\
y \\
1
\end{matrix}
\right) + 
\left(
\begin{matrix}
x + t_x \\
y + t_y \\
1
\end{matrix}
\right)
$$

#### 仿射变换（Affine Transformations）

既然有了齐次坐标系这么好的东西，那么我们就能思考如何将线性变换和平移变换进行表示，现在它们有了一个新的名字，我们称线性变换+平移变化 = 仿射变换。

需要注意的是，使用齐次坐标表示的变换矩阵是先进行线性变换再进行平移变换。
$$
\left(
\begin{matrix}
x' \\
y'
\end{matrix}
\right) = 
\left(
\begin{matrix}
a & b \\
c & d
\end{matrix}
\right)
\left(
\begin{matrix}
x \\
y
\end{matrix}
\right) + 
\left(
\begin{matrix}
t_x \\
t_y
\end{matrix}
\right) \\
\left(
\begin{matrix}
x' \\
y' \\
1
\end{matrix}
\right) = 
\left(
\begin{matrix}
a & b & t_x \\
c & d & t_y \\
0 & 0 & 1
\end{matrix}
\right)
\left(
\begin{matrix}
x \\
y \\
1
\end{matrix}
\right)
$$

### 变换的组合（Composite Transform）

对于默认为列向量，变换通常通过左乘变换矩阵实现，然后以从右到左的计算顺序计算变换的结果，由于矩阵的乘法没有交换率，因此变换的先后顺序变得极为重要。

但由于矩阵满足结合率，因此可以先将变换矩阵相乘后在应用到目标向量上。
$$
A_n(...A_2(A_1(x))) = (A_n ... A_2...A_1)
\left(
\begin{matrix}
x \\
y \\
1
\end{matrix}
\right)
$$

#### 逆变换（Inverse Transform）

逆变换即与某个变换效果相反的变换，在数学上，如果一个变换是通过左乘一个变换矩阵$M$完成的，那么它的逆变换就是变换后的向量左乘一个$M^{-1}$

#### 变换的分解（Decomposing Complex Transforms)

考虑这样一个问题：

1. 现在存在一个左下角c不在原点的矩形
2. 我们希望以矩形的左下角为基准将其旋转一个角度a

我们可以通过如下几个步骤完成这个操作：

1. 将c点平移到原点
2. 绕原点旋转角度a
3. 将c点移动回原位

![image-20220110162336178](E:\EnderBlogSource\EnderXiao.github.io\source\images\image-20220110162336178.png)

### 三维空间的变换

三维空间中我们同样希望使用齐次坐标系表示三维坐标中的点和向量，于是得到一个与二维空间类似的结果：

- 表示一个二维的点：$point = (x,y,z,1)^T$
- 表示一个二维的向量：$vector = (x,y,z,0)^T$

当w不为1且不为0时，齐次坐标系下的点$(x,y,z,w)$所表示的三维空间中的点为：$(x/w,y/w,z/w)$

同样三维空间中的仿射变换可以表示为如下形式：
$$
\left(
\begin{matrix}
x' \\
y' \\
z' \\
1
\end{matrix}
\right) = 
\left(
\begin{matrix}
a & b & c & t_x \\
d & e & f & t_y \\
g & h & i & t_z \\
0 & 0 & 0 & 1
\end{matrix}
\right)
\left(
\begin{matrix}
x \\
y \\
z \\
1
\end{matrix}
\right)
$$

> 二位变换补充：
>
> 在不考虑齐次坐标的情况下，旋转变换使用的矩阵是一个正交矩阵（Orthogonal Matrix），实际上他还是一个单位正交阵

#### 三维空间中的线性变换与平移变换

##### 缩放

$$
S(s_x, s_y, s_z) =
\left(
\begin{matrix}
s_x & 0 & 0 & 0 \\
0 & s_y & 0 & 0 \\
0 & 0 & s_z & 0 \\
0 & 0 & 0 & 1
\end{matrix}
\right)
$$

##### 平移

$$
T(t_x, t_y, t_z) =
\left(
\begin{matrix}
1 & 0 & 0 & t_x \\
0 & 1 & 0 & t_y \\
0 & 0 & 1 & t_z \\
0 & 0 & 0 & 1
\end{matrix}
\right)
$$

##### 旋转

###### x轴

$$
R_x(\alpha) =
\left(
\begin{matrix}
1 & 0 & 0 & 0 \\
0 & cos\alpha & -sin\alpha & 0 \\
0 & sin\alpha & cos\alpha & 0 \\
0 & 0 & 0 & 1
\end{matrix}
\right)
$$

###### y轴

$$
R_y(\alpha) =
\left(
\begin{matrix}
cos\alpha & 0 & sin\alpha & 0 \\
0 & 1 & 0 & 0 \\
-sin\alpha & 0 & cos\alpha & 0 \\
0 & 0 & 0 & 1
\end{matrix}
\right)
$$

###### z轴

$$
R_z(\alpha) =
\left(
\begin{matrix}
cos\alpha & -sin\alpha & 0 & 0 \\
sin\alpha & cos\alpha & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{matrix}
\right)
$$

对于如上公式，我们观察到，在对y轴进行旋转的矩阵中，如果将非0，1的数值提取出来组成2维变换矩阵，得到的变换矩阵与其余两个轴形成的变换矩阵刚好互为逆，这是为什么呢？
