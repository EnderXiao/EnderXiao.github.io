---
title: Tree-Transformer论文阅读
date: 2023-06-20 10:31:17
categories:
  - - 研究生
    - 科研
    - OCR
tags:
  - 手写体识别
  - 深度神经网络
  - 深度学习
  - 注意力机制
  - 树形编码器
headimg:
  'https://z3.ax1x.com/2021/08/05/fego40.png'
plugins:
  - mathjax
---
基于Transformer的Tree2Tree树形解码器
<!-- more -->

## 摘要

本文提出了一种在任意输入和输出树之间转化的新网络结构，并将其应用于源代码和自然语言领域的纠错任务中。

源代码任务上该模型取得的F0.5比最好的序列模型提升25%

在自然语言处理上取得了与最复杂的SOTA相当的结果，在CoNLL2014 benchmark上提升了10%的召回率，在AESW benchmark上的F0.5取得了50.43，达到了最高分

## intro

目前大多数机器学习的方法都是以序列作为输入或输出的，但这么做通常是因为处理起来更方便，而通常为了让序列化的文本仍然包含结构信息，需要按照某一特殊文法生成序列，例如**上下文无关文法(Context Free Grammar(CFG))**

本文训练了一个直接在树上操作的神经网络，教他学习底层语法的上下文信息，从而使得其可以在这样的上下文信息的指导下产生语法正确的输出。
