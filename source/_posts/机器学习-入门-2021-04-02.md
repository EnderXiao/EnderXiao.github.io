---
title: 机器学习——入门
categories:
  - - Machine Learning
    - 机器学习入门
tags:
  - Machine Learning
mathjax: true
date: 2021-04-02 11:01:41
---

机器学习简述



<!-- more -->

## 机器学习的定义

历史上主要有两位学者对机器学习进行过定义，反别是Arthur Samuel和Tom mitshell，下面分别给出介绍

### Arthur Samuel

Arthur Samuel——编写世界上第一个棋类游戏人工智能程序

他对于机器学习的定义如下：

{% note guide blue, def：


机器学习是，赋予计算机学习能力，且该能力不是通过显著式编程获得

%}



#### 非显著式编程
让计算机自己总结规律的编程方法

#### 收益函数：
我们通常规定正在特定环境下，计算机做某些行为会带来某些收益，我们称它为`收益函数`
在规定了行为和收益函数后，让计算机自己去找最大会收益函数的行为

### Tom mitshell
而Tom mitshell——在其书《Machine Learning》中对机器学习的定义为：

{% note guide blue, def：

机械学习，就是对于一个任务T，衡量完成T好换的性能指标P，以及计算机获得的经验E，计算机从经验E中学习，使得，计算机完成任务T的性能指标P逐步提升，即：计算机在T上的被P衡量的性能，会随着经验E的增加而提高

%}

## 机器学习任务的分类
### 监督学习

对于：

1. 垃圾邮件识别
2. 人脸识别

这类的机器学习任务，需要`为数据打标签`（Labeling for training data），才此情况下，经验E是是`训练样本`和`标签`的集合，由此我们可以得到监督学习的定义：

{% note guide blue, def：

所有经验E都是人工采集并输入计算机的，将这类输入计算机训练数据同时加上标签的机器学习称为监督学习(Supervised Learning)

%}

在此类机器学习中，算法必须知道预测什么，即目标变量的分类信息

此外还能通过数据标签的存在与否对监督学习进行分类，分为：

1. 传统监督学习
2. 半监督学习
3. 非监督学习

#### 传统监督学习

{% note guide blue, def：

传统监督学习(Traditional Supervised Learning)中，每一个数据标签都有数据标签

%}

传统学习中主要的算法有：

1. 支持向量机(Support Vector Machine)
2. 人工神经网络(Neural Networks)
3. 深度神经网络(Deep Neural Networks)

#### 非监督学习

{% note guide blue, def：

如果所有的训练数据都没有对应的标签，则称为非监督学习(Unsupervised Learning)

%}

非监督学习的数据中没有类别信息（标签），也不会给定目标值。在无监督学习中：

1. 将数据集合分成由了类似的对象组成的多个类的过程称为`聚类`；
2. 将寻找描述数据统计值的过程称为`密度估计`;

此外，非监督学习可以减少数据特征的维度，一遍我们可以使用二维或三维图形更直观的展示数据信息。

由定义，我们可能会产生一个问题，对于没有数据标签的数据，我们如何对数据进行分类。

对此我们需要做出如下假设：

1. 如果同一类的训练数据在空间中距离最近
2. 根据样本空间中的空间信息
3. 设计算法将它们聚集为两类

从而实现无监督学习，其中主要算法包括：

1. 聚类(Clustering)
2. EM算法(Expectation-Maximization algorithm)
3. 主成分分析(Principle Component Analysis)

#### 半监督学习

{% note guide blue, def：

如果训练数据中一部分由标签一部分没有标签，称这种机器学习为`半监督学习(Semi-Supervised Learning)`

%}



为了节约为数据打标签的成本，由于半监督学习使用`少量的标注数据`与`大量未标注数据`进行训练的特性，近年半监督学习逐渐成为热点

#### 另一种分类方式

基于标签的固有属性，我们可以将监督学习分为：

1. 分类
2. 回归

##### 分类

如果标签是`离散`的值，则将这种学习成为分类

如人脸识别算法，就是`分类`任务，如：

1. 给出两张人脸，判断是否为同一人，可以用0表示是，1表示否
2. 从大量照片中，按照人脸将照片分类，则可以用$1,\dots,N$表示不同的人

这些都是离散的值

##### 回归

如果标签是`连续`的值，则将这种学习成为回归

例如设计算法预测房价的走势，标签为平均房价，训练样本为时间

#### 总结

对于分类、回归、聚类、密度估计，在此将这些操作的相关算法以及能够解决的问题进行汇总

| 监督学习算法   | 算法用途              |
| -------------- | --------------------- |
| k-近邻算法     | 线性回归              |
| 朴素贝叶斯算法 | 局部加权线性回归      |
| 支持向量机     | Ridge回归             |
| 决策树         | Lasso最小回归系数估计 |

| 非监督学习算法 | 算法用途     |
| -------------- | ------------ |
| K-均值         | 最大期望算法 |
| DBSCAN         | Parzen窗设计 |



### 强化学习

对于：

1. 下棋
2. 自动驾驶

这类机器学习任务，经验E是由计算机`与环境互动`获得的，我们只需要定义这些行为的`收益函数(Reward Function)`，对行为进行奖励和乘法，并且计算机能够根据这些奖励和乘法，改变自己的行为模式，从而`最大化收益函数`

由此可以得到强化学习的定义：

计算机通过与环境的互动逐渐强化自己的行为模式的机器学习称为强化学习(Reinforcement Learning) 

但对于AlphaGo而言，起初是通过监督学习，通过高手对局的视频，形成一个初始的围棋程序，在对该程序进行强化学习提成其性能。

## 机器学习算法的过程

1. 特征提取(Feature Extraction)：

   在这一步中会从样本中抽象出一些用于做分类的特征

2. 特征选择(Feature Selection)

   从1中抽象出的特征中分析，选出最能有效进行分类的特征，以此构建机器学习系统 

3. 根据2中选出的特征构建特征空间(Feature Space)

4. 选用不同的算法对特征空间进行划分

   基于2中选择的特征构建算法

> PS:
>
> 对于3中选择算法这一步，比如可以选择：
>
> 支持向量机(Support Vector Machine)，其中包含三种内核：
>
> 1. 线性内核
> 2. 多项式核
> 3. 高斯径向基函数核

再次列举一个构建特征空间的例子，特征空间可以按照特征的个数任意指定维数：

[<img src="https://i.postimg.cc/MT7M0PVP/image.png" alt="image.png" style="zoom:150%;" />](https://postimg.cc/gX02mKM8)

在特征空间中包含的几个关键词：

1. 维度

   人对于三维以上的事物缺乏想象力，但目前的机器学习算法可以较为精确的处理三维以上的数据

2. 标准

   使用不同的标准，对某一些区域的划分会有区别

## 没有免费午餐定理

{% note guide cyan, 定理 4.1

1995年,D.H.Wolpert等人提出：

No Free Lunch Theorem(没有免费午餐定理?)

任何一个预测函数，如果在一些训练样本上表现好，那么必然在另一些训练样本上表现不好，如果不对数据在特定空间的`先验分布`有一定假设，那么表现好与不好的情况将会一样多

%}

因此没有任何情况下都最优的机器学习方法

对于NFL定理中提及的先验分布而言，我们可以用如下例子进行理解：

[<img src="https://i.postimg.cc/sXdGhdQG/NFL.png" alt="NFL.png" style="zoom:150%;" />](https://postimg.cc/3y1xsqZ3)



其中`空间上距离接近的样本它们属于同一个类别的概论更高`就是一种先验分布，这就意味着机器学习算法是基于某些先验分布来进行预测的学科。

这就意味着在学习过程中，我们不能片面夸大某个定理的作用，要对开发新的算法保持探索的精神。

**此外该定理还提醒了我们机器学习的本质：基于有限的已知数据，在复杂的高维特征空间中预测未知样本的属性和类别**

## 如何选用合适的算法

选用机器学习算法需要考虑以下几个问题：

1. 使用机器学习算法的目的
2. 想要完成的任务
3. 了解数据的特征

- 首先考虑机器学习`算法的目的`以及想要完成的`任务`：
  1. 如果要预测目标变量的值，则可以选择监督学习算法；
  2. 否则可以选择无监督学习算法。
  3. 确定选择监督学习算法后，需要进一步明确目标变量的类型：
     1. 如果目标变量是离散型，则可以选择分类算法；
     2. 如果是连续性，则可以使用回归算法
- 其次需要考虑实际的数据，应该充分了解数据，对数据了解的越充分，越容易创建符合实际需要的应用程序，主要应该了解数据的以下几个特征：
  1. 特征值是`离散型`变量还是`连续型`变量
  2. 特征值中是否有`缺失的值`，何种`原因`造成
  3. 数据中是否有`异常值`
  4. 某些特征发生的`频率`如何
- 通过对数据的充分了解，可以帮助我们缩小算法的选择范围，而由NFL定理可以知道，一般并不存在最好的算法和可以给出最好效果的算法，一般发现最好算法的关键环节就是反复`调试`和`迭代`



## 开发机器学习应用程序的步骤

1. 收集数据：通过多种手段收集数据，比如`爬虫`等，也可以使用`开源数据源`
2. 准备输入数据：
   1. 得到数据之后，还必须确保数据格式符合要求，使用`标准的数据格式`可以融合算法和数据源，方便匹配操作
   2. 还要为机器学习算法准备`特定的数据格式`，一般某些算法要求目标变量和特征值是字符串，而另一些算法要求是整型
3. 分析输入数据：主要是人工分析得到的数据，确保数据中没有`垃圾数据`
4. 训练算法：将前两步得到的格式化数据输入到算法，从中抽取信息
5. 测试算法：
   1. 对于监督学习，必须已知用于评估算法的目标变量值
   2. 对于非监督学习，也必须用其他评测手段来检验算法的成功率
   3. 如果不满意算法的输出结果，不改变算法的前提下，问题常常与数据的收集和准备有关
6. 使用算法：将机器学习算法转化为应用程序，执行实际任务，以检验上述步骤是否可以在实际环境中运行

